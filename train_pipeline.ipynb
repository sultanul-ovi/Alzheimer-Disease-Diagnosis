{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, roc_auc_score\n",
        ")\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters / Config\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 20\n",
        "LR_HEAD = 3e-4\n",
        "LR_BACKBONE = 1e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "LABEL_SMOOTH = 0.02\n",
        "HEAD_WARMUP_EPOCHS = 3\n",
        "USE_MIXUP = False\n",
        "MIXUP_ALPHA = 0.2\n",
        "USE_TTA = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset path: C:\\Users\\sajib/.cache/kagglehub/datasets/ninadaithal/imagesoasis/versions/1\\Data\n",
            "Classes: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\n"
          ]
        }
      ],
      "source": [
        "# Dataset discovery from KaggleHub-style layout or explicit path\n",
        "EXPECTED_CLASSES = ['Non Demented', 'Very mild Dementia', 'Mild Dementia', 'Moderate Dementia']\n",
        "\n",
        "def resolve_dataset_path(root_candidates):\n",
        "    for root in root_candidates:\n",
        "        if not root:\n",
        "            continue\n",
        "        candidates = [os.path.join(root, 'Data'), root]\n",
        "        for cand in candidates:\n",
        "            if os.path.isdir(cand):\n",
        "                subdirs = [d for d in os.listdir(cand) if os.path.isdir(os.path.join(cand, d))]\n",
        "                found = [d for d in subdirs if d in EXPECTED_CLASSES]\n",
        "                if len(found) == len(EXPECTED_CLASSES):\n",
        "                    return cand, found\n",
        "                if len(found) > 0:\n",
        "                    return cand, found\n",
        "    return None, []\n",
        "\n",
        "\n",
        "DATASET_ROOT = os.environ.get('ALZ_DATASET_ROOT', None)\n",
        "\n",
        "\n",
        "common_roots = [\n",
        "    DATASET_ROOT,\n",
        "    os.path.expanduser(r\"~/.cache/kagglehub/datasets/ninadaithal/imagesoasis/versions/1\"),\n",
        "    os.path.expanduser(r\"~/kaggle/input/imagesoasis\"),\n",
        "    r\"C:\\\\Users\\\\sajib\\\\.cache\\\\kagglehub\\\\datasets\\\\ninadaithal\\\\imagesoasis\\\\versions\\\\1\",\n",
        "]\n",
        "\n",
        "dataset_path, class_names = resolve_dataset_path(common_roots)\n",
        "if not dataset_path:\n",
        "    raise FileNotFoundError(\"Could not resolve dataset path. Set ALZ_DATASET_ROOT to the dataset root or adjust common_roots.\")\n",
        "\n",
        "print(f\"Dataset path: {dataset_path}\")\n",
        "print(f\"Classes: {class_names}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class AlzheimerDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = {\n",
        "            'Non Demented': 0,\n",
        "            'Very mild Dementia': 1,\n",
        "            'Mild Dementia': 2,\n",
        "            'Moderate Dementia': 3\n",
        "        }\n",
        "        if len(self.labels) > 0 and isinstance(self.labels[0], str):\n",
        "            self.labels = [self.class_to_idx[lbl] for lbl in self.labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.image_paths[idx]).convert('L')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "\n",
        "\n",
        "def get_transforms(img_size=224, is_training=False):\n",
        "    if is_training:\n",
        "        return T.Compose([\n",
        "            T.RandomResizedCrop(img_size, scale=(0.8, 1.0), ratio=(0.95, 1.05)),\n",
        "            T.RandomHorizontalFlip(p=0.5),\n",
        "            T.RandomRotation(degrees=10),\n",
        "            T.Grayscale(num_output_channels=3),\n",
        "            T.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    else:\n",
        "        return T.Compose([\n",
        "            T.Resize(int(img_size*1.14)),\n",
        "            T.CenterCrop(img_size),\n",
        "            T.Grayscale(num_output_channels=3),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 86437\n",
            "Class weights: [0.21495749 0.47572607 0.7879393  2.521377  ]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def load_and_split(dataset_path, class_names, test_size=0.15, val_size=0.15, random_state=SEED):\n",
        "    image_paths, labels = [], []\n",
        "    for cls in class_names:\n",
        "        cls_dir = os.path.join(dataset_path, cls)\n",
        "        files = [f for f in os.listdir(cls_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        for f in files:\n",
        "            image_paths.append(os.path.join(cls_dir, f))\n",
        "            labels.append(cls)\n",
        "    print(f\"Total images: {len(image_paths)}\")\n",
        "\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        image_paths, labels, test_size=test_size, stratify=labels, random_state=random_state\n",
        "    )\n",
        "    val_size_adjusted = val_size / (1 - test_size)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=val_size_adjusted, stratify=y_temp, random_state=random_state\n",
        "    )\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "\n",
        "def make_loaders(dataset_path, class_names, batch_size=BATCH_SIZE, img_size=IMG_SIZE, num_workers=0):\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_and_split(dataset_path, class_names)\n",
        "\n",
        "    train_tf = get_transforms(img_size, True)\n",
        "    eval_tf = get_transforms(img_size, False)\n",
        "\n",
        "    train_ds = AlzheimerDataset(X_train, y_train, train_tf)\n",
        "    val_ds = AlzheimerDataset(X_val, y_val, eval_tf)\n",
        "    test_ds = AlzheimerDataset(X_test, y_test, eval_tf)\n",
        "\n",
        "   \n",
        "    num_classes = 4\n",
        "    train_label_tensor = torch.tensor(train_ds.labels, dtype=torch.long)\n",
        "    binc = torch.bincount(train_label_tensor, minlength=num_classes).float()\n",
        "    binc[binc == 0] = 1.0\n",
        "    inv_sqrt = (1.0 / torch.sqrt(binc))\n",
        "    class_weights = (inv_sqrt / inv_sqrt.sum()) * num_classes  # moderate\n",
        "    print(f\"Class weights: {class_weights.numpy()}\")\n",
        "\n",
        "   \n",
        "    per_sample_w = (1.0 / torch.sqrt(binc))[train_label_tensor]\n",
        "    sampler = WeightedRandomSampler(weights=per_sample_w, num_samples=len(per_sample_w), replacement=True)\n",
        "\n",
        "    loaders = {\n",
        "        'train': DataLoader(train_ds, batch_size=batch_size, sampler=sampler, shuffle=False, num_workers=num_workers, pin_memory=False),\n",
        "        'val': DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=False),\n",
        "        'test': DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=False),\n",
        "        'class_weights': class_weights\n",
        "    }\n",
        "    return loaders, {'class_names': class_names}\n",
        "\n",
        "loaders, meta = make_loaders(dataset_path, class_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Models\n",
        "\n",
        "def create_model(name: str, num_classes: int = 4, pretrained: bool = True) -> nn.Module:\n",
        "    if name == 'vgg16':\n",
        "        m = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        m.classifier[6] = nn.Linear(4096, num_classes)\n",
        "        return m\n",
        "    if name == 'vgg19':\n",
        "        m = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        m.classifier[6] = nn.Linear(4096, num_classes)\n",
        "        return m\n",
        "    if name == 'resnet50':\n",
        "        m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None)\n",
        "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "        return m\n",
        "    if name == 'resnet101':\n",
        "        m = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V2 if pretrained else None)\n",
        "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "        return m\n",
        "    if name == 'resnet152':\n",
        "        m = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V2 if pretrained else None)\n",
        "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "        return m\n",
        "    if name == 'densenet121':\n",
        "        m = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        m.classifier = nn.Linear(m.classifier.in_features, num_classes)\n",
        "        return m\n",
        "    if name == 'densenet201':\n",
        "        m = models.densenet201(weights=models.DenseNet201_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        m.classifier = nn.Linear(m.classifier.in_features, num_classes)\n",
        "        return m\n",
        "    if name == 'mobilenetv3_large':\n",
        "        m = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V2 if pretrained else None)\n",
        "        m.classifier[3] = nn.Linear(m.classifier[3].in_features, num_classes)\n",
        "        return m\n",
        "    if name == 'shufflenet_v2_x1_0':\n",
        "        m = models.shufflenet_v2_x1_0(weights=models.ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "        return m\n",
        "    raise ValueError(f\"Unknown model: {name}\")\n",
        "\n",
        "ALL_MODELS = [\n",
        "    'vgg16', 'vgg19',\n",
        "    'resnet50', 'resnet101', 'resnet152',\n",
        "    'densenet121', 'densenet201',\n",
        "    'mobilenetv3_large', 'shufflenet_v2_x1_0'\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def one_hot_targets(labels, num_classes=4, smoothing=LABEL_SMOOTH):\n",
        "    with torch.no_grad():\n",
        "        true_dist = torch.zeros((labels.size(0), num_classes), device=labels.device)\n",
        "        true_dist.fill_(smoothing / (num_classes - 1))\n",
        "        true_dist.scatter_(1, labels.unsqueeze(1), 1.0 - smoothing)\n",
        "    return true_dist\n",
        "\n",
        "\n",
        "def mixup_data(x, y, alpha=MIXUP_ALPHA):\n",
        "    if alpha <= 0:\n",
        "        return x, y, 1.0\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, (y_a, y_b), lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, epoch):\n",
        "    \n",
        "    use_mixup = (epoch < max(HEAD_WARMUP_EPOCHS + 2, 4)) and USE_MIXUP\n",
        "    model.train()\n",
        "    scaler = GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    pbar = tqdm(loader, desc=f\"Train {epoch+1}\")\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast(enabled=torch.cuda.is_available()):\n",
        "            if use_mixup:\n",
        "                images, (ya, yb), lam = mixup_data(images, labels, MIXUP_ALPHA)\n",
        "                outputs = model(images)\n",
        "                loss = mixup_criterion(criterion, outputs, ya, yb, lam)\n",
        "            else:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = outputs.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += images.size(0)\n",
        "        pbar.set_postfix(loss=running_loss/total, acc=correct/total)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "\n",
        "def eval_epoch(model, loader, criterion, epoch, phase=\"Val\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    pbar = tqdm(loader, desc=f\"{phase} {epoch+1}\")\n",
        "    all_probs, all_labels, all_preds = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in pbar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            with autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            preds = outputs.argmax(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += images.size(0)\n",
        "            all_probs.append(probs.detach().cpu())\n",
        "            all_labels.append(labels.detach().cpu())\n",
        "            all_preds.append(preds.detach().cpu())\n",
        "            pbar.set_postfix(loss=running_loss/total, acc=correct/total)\n",
        "    all_probs = torch.cat(all_probs).numpy()\n",
        "    all_labels = torch.cat(all_labels).numpy()\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    return running_loss/total, correct/total, all_probs, all_labels, all_preds\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train_model(name, loaders, num_epochs=NUM_EPOCHS, lr=LR_BACKBONE, weight_decay=WEIGHT_DECAY):\n",
        "    print(f\"\\n==== Training {name} ====\")\n",
        "    model = create_model(name, num_classes=4, pretrained=True).to(device)\n",
        "    class_weights = loaders['class_weights'].to(device)\n",
        "    base_criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTH)\n",
        "\n",
        "\n",
        "    head_params, backbone_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if any(k in n for k in ['fc', 'classifier']):\n",
        "            head_params.append(p)\n",
        "        else:\n",
        "            backbone_params.append(p)\n",
        "    optimizer = optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': lr},\n",
        "        {'params': head_params, 'lr': LR_HEAD}\n",
        "    ], weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "    best_acc = 0.0\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch < HEAD_WARMUP_EPOCHS:\n",
        "            for p in backbone_params:\n",
        "                p.requires_grad = False\n",
        "        else:\n",
        "            for p in backbone_params:\n",
        "                p.requires_grad = True\n",
        "\n",
        "        tr_loss, tr_acc = train_epoch(model, loaders['train'], base_criterion, optimizer, epoch)\n",
        "        va_loss, va_acc, va_probs, va_labels, va_preds = eval_epoch(model, loaders['val'], base_criterion, epoch, phase='Val')\n",
        "        history['train_loss'].append(tr_loss)\n",
        "        history['train_acc'].append(tr_acc)\n",
        "        history['val_loss'].append(va_loss)\n",
        "        history['val_acc'].append(va_acc)\n",
        "        scheduler.step()\n",
        "        # extra metrics\n",
        "        va_precision = precision_score(va_labels, va_preds, average='macro', zero_division=0)\n",
        "        va_recall = recall_score(va_labels, va_preds, average='macro', zero_division=0)\n",
        "        va_f1 = f1_score(va_labels, va_preds, average='macro', zero_division=0)\n",
        "        print(f\"Epoch {epoch+1}: train_acc={tr_acc:.4f} val_acc={va_acc:.4f} val_f1={va_f1:.4f} val_prec={va_precision:.4f} val_rec={va_recall:.4f}\")\n",
        "        if va_acc > best_acc:\n",
        "            best_acc = va_acc\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    te_loss, te_acc, te_probs, te_labels, te_preds = eval_epoch(model, loaders['test'], base_criterion, -1, phase='Test')\n",
        "\n",
        "    if USE_TTA:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            tta_probs = []\n",
        "            for images, _ in tqdm(loaders['test'], desc='TTA'):\n",
        "                images = images.to(device)\n",
        "                p1 = F.softmax(model(images), dim=1)\n",
        "                p2 = F.softmax(model(torch.flip(images, dims=[3])), dim=1)\n",
        "                tta_probs.append(((p1 + p2) / 2).cpu())\n",
        "            te_probs = torch.cat(tta_probs).numpy()\n",
        "\n",
        "    try:\n",
        "        y_true_bin = F.one_hot(torch.tensor(te_labels), num_classes=4).numpy()\n",
        "        auc_macro = roc_auc_score(y_true_bin, te_probs, average='macro', multi_class='ovr')\n",
        "    except Exception:\n",
        "        auc_macro = 0.0\n",
        "\n",
        "    # detailed test metrics\n",
        "    te_precision = precision_score(te_labels, te_preds, average='macro', zero_division=0)\n",
        "    te_recall = recall_score(te_labels, te_preds, average='macro', zero_division=0)\n",
        "    te_f1 = f1_score(te_labels, te_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test: acc={te_acc:.4f} f1={te_f1:.4f} prec={te_precision:.4f} rec={te_recall:.4f} auc_macro={auc_macro:.4f}\")\n",
        "    print(f\"Model: {name} | ImgSize: {IMG_SIZE} | Batch: {BATCH_SIZE} | Epochs: {NUM_EPOCHS} | LR(head/backbone): {LR_HEAD}/{LR_BACKBONE} | Warmup: {HEAD_WARMUP_EPOCHS}\")\n",
        "\n",
        "    return {\n",
        "        'model_name': name,\n",
        "        'best_val_acc': best_acc,\n",
        "        'test_acc': te_acc,\n",
        "        'test_f1_macro': te_f1,\n",
        "        'test_precision_macro': te_precision,\n",
        "        'test_recall_macro': te_recall,\n",
        "        'test_auc_macro': auc_macro,\n",
        "        'config': {\n",
        "            'img_size': IMG_SIZE,\n",
        "            'batch_size': BATCH_SIZE,\n",
        "            'num_epochs': NUM_EPOCHS,\n",
        "            'lr_head': LR_HEAD,\n",
        "            'lr_backbone': LR_BACKBONE,\n",
        "            'weight_decay': WEIGHT_DECAY,\n",
        "            'label_smooth': LABEL_SMOOTH,\n",
        "            'warmup_epochs': HEAD_WARMUP_EPOCHS,\n",
        "            'mixup': USE_MIXUP\n",
        "        },\n",
        "        'history': history,\n",
        "        'state_dict': best_state\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training resnet50\n",
            "\n",
            "==== Training resnet50 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sajib\\AppData\\Local\\Temp\\ipykernel_26716\\1909904483.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler('cuda', enabled=torch.cuda.is_available())\n",
            "Train 1:   0%|          | 0/1891 [00:00<?, ?it/s]C:\\Users\\sajib\\AppData\\Local\\Temp\\ipykernel_26716\\1909904483.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=torch.cuda.is_available()):\n",
            "Train 1:   0%|          | 0/1891 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error training resnet50: full() received an invalid combination of arguments - got (tuple, str, device=torch.device, dtype=torch.dtype), but expected one of:\n",
            " * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
            " * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
            "\n",
            "Training resnet101\n",
            "\n",
            "==== Training resnet101 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train 1:   0%|          | 0/1891 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error training resnet101: full() received an invalid combination of arguments - got (tuple, str, device=torch.device, dtype=torch.dtype), but expected one of:\n",
            " * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
            " * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
            "\n",
            "Training resnet152\n",
            "\n",
            "==== Training resnet152 ====\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-f82ba261.pth\" to C:\\Users\\sajib/.cache\\torch\\hub\\checkpoints\\resnet152-f82ba261.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 62.5M/230M [00:40<01:02, 2.81MB/s]"
          ]
        }
      ],
      "source": [
        "\n",
        "results = []\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "\n",
        "priority_models = [\n",
        "    'resnet50', 'resnet101', 'resnet152'\n",
        "]\n",
        "\n",
        "for name in priority_models:\n",
        "    try:\n",
        "        print(f\"Training {name}\")\n",
        "        res = train_model(name, loaders)\n",
        "        results.append(res)\n",
        "        torch.save({\n",
        "            'model_name': name,\n",
        "            'state_dict': res['state_dict'],\n",
        "            'history': res['history'],\n",
        "            'meta': meta,\n",
        "            'results': {k: res[k] for k in ['best_val_acc', 'test_acc', 'test_auc_macro']}\n",
        "        }, os.path.join('models', f'{name}_finetuned.pth'))\n",
        "    except Exception as e:\n",
        "        print(f\"Error training {name}: {e}\")\n",
        "\n",
        "\n",
        "if results:\n",
        "    df = pd.DataFrame([\n",
        "        {\n",
        "            'model': r['model_name'],\n",
        "            'val_acc': r['best_val_acc'],\n",
        "            'test_acc': r['test_acc'],\n",
        "            'test_f1_macro': r.get('test_f1_macro', None),\n",
        "            'test_precision_macro': r.get('test_precision_macro', None),\n",
        "            'test_recall_macro': r.get('test_recall_macro', None),\n",
        "            'test_auc_macro': r['test_auc_macro'],\n",
        "            'img_size': r['config']['img_size'],\n",
        "            'batch_size': r['config']['batch_size'],\n",
        "            'epochs': r['config']['num_epochs'],\n",
        "            'lr_head': r['config']['lr_head'],\n",
        "            'lr_backbone': r['config']['lr_backbone'],\n",
        "            'weight_decay': r['config']['weight_decay'],\n",
        "            'label_smooth': r['config']['label_smooth'],\n",
        "            'warmup_epochs': r['config']['warmup_epochs'],\n",
        "            'mixup': r['config']['mixup']\n",
        "        }\n",
        "        for r in results\n",
        "    ])\n",
        "    print(df.sort_values('test_acc', ascending=False))\n",
        "    df.to_csv('models/summary.csv', index=False)\n",
        "else:\n",
        "    print(\"No models trained.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
